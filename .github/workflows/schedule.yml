name: Scheduled scraper run

on:
  schedule:
    # 19:30 JST / 10:30 UTC every day
    - cron: '30 10 * * *'
  workflow_dispatch:

jobs:
  run-scraper:
    runs-on: ubuntu-latest
    env:
      EDINET_CODE: ${{ vars.EDINET_CODE || 'E35239' }}
      EDINET_API_KEY: ${{ secrets.EDINET_API_KEY }}
      DOWNLOAD_DIR: ${{ vars.DOWNLOAD_DIR || 'data/downloads' }}
      LINE_CHANNEL_ACCESS_TOKEN: ${{ secrets.LINE_CHANNEL_ACCESS_TOKEN }}
      LINE_CHANNEL_SECRET: ${{ secrets.LINE_CHANNEL_SECRET }}
      LINE_USER_ID: ${{ secrets.LINE_USER_ID }}
      DB_PATH: ${{ vars.DB_PATH || 'data/database/edinet_reports.db' }}

    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Poetry
        uses: snok/install-poetry@v1
        with:
          version: 1.7.1
          virtualenvs-create: true
          virtualenvs-in-project: true

      - name: Install dependencies
        run: poetry install --no-interaction --no-root

      - name: Run scraper
        env:
          PYTHONUNBUFFERED: '1'
        run: poetry run python run_scraper.py
