#!/usr/bin/env python3
"""
ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
LINEé€šçŸ¥ãªã—ã§ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã™
"""

import sys
import os
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.join(os.path.dirname(__file__)))

from src.utils.archive_manager import ArchiveManager
from src.utils.db import ReportDatabase

def test_archive_functionality():
    """ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    try:
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ†ã‚¹ãƒˆ
        print("\n1ï¸âƒ£ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ†ã‚¹ãƒˆ")
        db = ReportDatabase()
        
        # ç¾åœ¨ã®ãƒ¬ã‚³ãƒ¼ãƒ‰çŠ¶æ³ã‚’ç¢ºèª
        db.cursor.execute('SELECT COUNT(*) FROM processed_reports')
        total_count = db.cursor.fetchone()[0]
        print(f"ğŸ“Š ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {total_count}ä»¶")
        
        # file_locationã®çŠ¶æ³ã‚’ç¢ºèª
        db.cursor.execute('SELECT file_location, COUNT(*) FROM processed_reports GROUP BY file_location')
        location_stats = db.cursor.fetchall()
        print("ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«å ´æ‰€åˆ¥çµ±è¨ˆ:")
        for location, count in location_stats:
            print(f"  - {location}: {count}ä»¶")
        
        db.close()
        
        # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®ãƒ†ã‚¹ãƒˆ
        print("\n2ï¸âƒ£ ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ")
        archive_manager = ArchiveManager(
            download_dir="data/downloads",
            archive_dir="data/archives"
        )
        print("âœ… ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼åˆæœŸåŒ–æˆåŠŸ")
        
        # çµ±è¨ˆæƒ…å ±ã®å–å¾—ãƒ†ã‚¹ãƒˆ
        print("\n3ï¸âƒ£ çµ±è¨ˆæƒ…å ±å–å¾—ãƒ†ã‚¹ãƒˆ")
        stats = archive_manager.get_archive_statistics()
        print("ğŸ“Š ç¾åœ¨ã®çµ±è¨ˆæƒ…å ±:")
        print(f"  - ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚µã‚¤ã‚º: {stats.get('total_archive_size_mb', 0):.2f} MB")
        print(f"  - ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {stats.get('archive_file_count', 0)}å€‹")
        
        location_stats = stats.get('location_stats', {})
        for location, data in location_stats.items():
            print(f"  - {location}: {data.get('count', 0)}ä»¶")
        
        # ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³: ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å¯¾è±¡ã®ç¢ºèª
        print("\n4ï¸âƒ£ ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å¯¾è±¡ã®ç¢ºèªï¼ˆãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ï¼‰")
        print("ä¿æŒæœŸé–“ã‚’1æ—¥ã«è¨­å®šã—ã¦ãƒ†ã‚¹ãƒˆ...")
        
        from datetime import datetime, timedelta
        retention_days = 1
        cutoff_date = (datetime.now() - timedelta(days=retention_days)).strftime('%Y-%m-%d %H:%M:%S')
        print(f"ã‚«ãƒƒãƒˆã‚ªãƒ•æ—¥æ™‚: {cutoff_date}")
        
        db = ReportDatabase()
        cursor = db.cursor
        cursor.execute('''
        SELECT report_id, target_company, security_code, holder_name, 
               processed_at, importance_level, file_location
        FROM processed_reports 
        WHERE processed_at < ? 
        AND file_location = 'active'
        ORDER BY processed_at DESC
        ''', (cutoff_date,))
        
        candidates = cursor.fetchall()
        print(f"ğŸ¯ ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å¯¾è±¡: {len(candidates)}ä»¶")
        
        if candidates:
            print("\nè©³ç´°ï¼ˆæœ€åˆã®5ä»¶ï¼‰:")
            for i, record in enumerate(candidates[:5], 1):
                record_dict = dict(zip([col[0] for col in cursor.description], record))
                print(f"  {i}. {record_dict['target_company']} - {record_dict['holder_name']}")
                print(f"     ID: {record_dict['report_id']}")
                print(f"     å‡¦ç†æ—¥: {record_dict['processed_at']}")
                print(f"     é‡è¦åº¦: {record_dict['importance_level']}")
                print()
        
        db.close()
        
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç¢ºèª
        print("5ï¸âƒ£ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç¢ºèª")
        download_dir = Path("data/downloads")
        if download_dir.exists():
            dirs = [d for d in download_dir.iterdir() if d.is_dir() and d.name != 'logs']
            print(f"ğŸ“ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ•°: {len(dirs)}å€‹")
            
            total_size = 0
            for d in dirs:
                size = sum(f.stat().st_size for f in d.rglob('*') if f.is_file())
                total_size += size
            
            print(f"ğŸ’¾ ç·ã‚µã‚¤ã‚º: {total_size / (1024*1024):.2f} MB")
            
            if dirs:
                print("ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä¾‹ï¼ˆæœ€åˆã®3å€‹ï¼‰:")
                for d in dirs[:3]:
                    size = sum(f.stat().st_size for f in d.rglob('*') if f.is_file())
                    file_count = len([f for f in d.rglob('*') if f.is_file()])
                    print(f"  - {d.name}: {file_count}ãƒ•ã‚¡ã‚¤ãƒ«, {size / 1024:.1f} KB")
        
        print("\nâœ… ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆå®Œäº†")
        print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print("  1. å®Ÿéš›ã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å®Ÿè¡Œ: python test_archive.py --execute")
        print("  2. æœ¬æ ¼çš„ãªã‚¢ãƒ¼ã‚«ã‚¤ãƒ–: python run_archive_cleanup.py --dry-run")
        print("  3. çµ±è¨ˆæƒ…å ±ç¢ºèª: python test_archive.py --stats")
        
        return True
        
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        import traceback
        traceback.print_exc()
        return False

def execute_archive(retention_days=1):
    """å®Ÿéš›ã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å‡¦ç†ã‚’å®Ÿè¡Œ"""
    print(f"ğŸ—œï¸  å®Ÿéš›ã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å‡¦ç†ã‚’å®Ÿè¡Œï¼ˆä¿æŒæœŸé–“: {retention_days}æ—¥ï¼‰")
    
    try:
        archive_manager = ArchiveManager(
            download_dir="data/downloads",
            archive_dir="data/archives"
        )
        
        # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å®Ÿè¡Œ
        stats = archive_manager.archive_files_by_importance(retention_days)
        
        print("âœ… ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å‡¦ç†å®Œäº†")
        print(f"  ğŸ“ ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–æ¸ˆã¿: {stats['archived_count']}ä»¶")
        print(f"  âŒ å¤±æ•—: {stats['failed_count']}ä»¶")
        print(f"  ğŸ’¾ ç¯€ç´„å®¹é‡: {stats['total_size_saved'] / (1024*1024):.2f} MB")
        
        return True
        
    except Exception as e:
        print(f"âŒ ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False

def show_statistics():
    """çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º"""
    print("ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆæƒ…å ±")
    
    try:
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆ
        db = ReportDatabase()
        
        db.cursor.execute('SELECT COUNT(*) FROM processed_reports')
        total_count = db.cursor.fetchone()[0]
        
        db.cursor.execute('SELECT file_location, COUNT(*) FROM processed_reports GROUP BY file_location')
        location_stats = db.cursor.fetchall()
        
        db.cursor.execute('SELECT report_type, COUNT(*) FROM processed_reports GROUP BY report_type')
        type_stats = db.cursor.fetchall()
        
        print(f"\nğŸ“‹ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆ:")
        print(f"  ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {total_count}ä»¶")
        
        print("  ãƒ•ã‚¡ã‚¤ãƒ«å ´æ‰€åˆ¥:")
        for location, count in location_stats:
            print(f"    - {location}: {count}ä»¶")
        
        print("  å ±å‘Šæ›¸ç¨®åˆ¥:")
        for report_type, count in type_stats:
            print(f"    - {report_type}: {count}ä»¶")
        
        db.close()
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆ
        download_dir = Path("data/downloads")
        archive_dir = Path("data/archives")
        
        print(f"\nğŸ’¾ ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸çµ±è¨ˆ:")
        
        if download_dir.exists():
            active_dirs = [d for d in download_dir.iterdir() if d.is_dir() and d.name != 'logs']
            active_size = 0
            for d in active_dirs:
                active_size += sum(f.stat().st_size for f in d.rglob('*') if f.is_file())
            
            print(f"  ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ•ã‚¡ã‚¤ãƒ«:")
            print(f"    - ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ•°: {len(active_dirs)}å€‹")
            print(f"    - ç·ã‚µã‚¤ã‚º: {active_size / (1024*1024):.2f} MB")
        
        if archive_dir.exists():
            archive_files = list(archive_dir.glob('**/*.tar.gz'))
            archive_size = sum(f.stat().st_size for f in archive_files)
            
            print(f"  ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ•ã‚¡ã‚¤ãƒ«:")
            print(f"    - ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(archive_files)}å€‹")
            print(f"    - ç·ã‚µã‚¤ã‚º: {archive_size / (1024*1024):.2f} MB")
            
            if len(archive_files) > 0 and active_size > 0:
                total_size = active_size + archive_size
                print(f"  å…¨ä½“:")
                print(f"    - ç·ã‚µã‚¤ã‚º: {total_size / (1024*1024):.2f} MB")
                print(f"    - ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ç‡: {(archive_size / total_size) * 100:.1f}%")
        
        return True
        
    except Exception as e:
        print(f"âŒ çµ±è¨ˆæƒ…å ±å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆãƒ»ç®¡ç†')
    parser.add_argument('--execute', action='store_true', help='å®Ÿéš›ã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã‚’å®Ÿè¡Œ')
    parser.add_argument('--stats', action='store_true', help='çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º')
    parser.add_argument('--retention-days', type=int, default=1, help='ä¿æŒæœŸé–“ï¼ˆæ—¥æ•°ï¼‰')
    
    args = parser.parse_args()
    
    if args.stats:
        success = show_statistics()
    elif args.execute:
        success = execute_archive(args.retention_days)
    else:
        success = test_archive_functionality()
    
    if not success:
        sys.exit(1)

if __name__ == "__main__":
    main()
